{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f3bccf85",
      "metadata": {
        "id": "f3bccf85"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (56, 56, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# reshape to write input shape\n",
        "x_train = np.array([cv2.cvtColor(cv2.resize(x, input_shape[:2], \n",
        "                                            interpolation = cv2.INTER_AREA),cv2.COLOR_GRAY2RGB) for x in x_train])\n",
        "x_test = np.array([cv2.cvtColor(cv2.resize(x, input_shape[:2], \n",
        "                                           interpolation = cv2.INTER_AREA),cv2.COLOR_GRAY2RGB) for x in x_test])\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "# preprocess input\n",
        "plt.imshow(x_train[0])\n",
        "\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "9mi4irSKQv-7",
        "outputId": "ce979b27-c50a-4caa-9ec5-3d27f0b0b4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "id": "9mi4irSKQv-7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 56, 56, 3)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.MobileNet(\n",
        "    input_shape=input_shape,\n",
        "    alpha=1.0,\n",
        "    depth_multiplier=1,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "1ekUgYO6XZv2",
        "outputId": "f8e731e0-2e3f-4e8e-f642-934217515a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1ekUgYO6XZv2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_augmentation(np_tensor):\n",
        " \n",
        "  def random_crop(np_tensor):\n",
        " \n",
        "    #cropped height between 70% to 130% of an original height\n",
        "    new_height = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[0])\n",
        " \n",
        "    #cropped width between 70% to 130% of an original width\n",
        "    new_width = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[1])\n",
        " \n",
        "    # resize to new height and width\n",
        "    cropped = tf.image.resize_with_crop_or_pad(np_tensor, new_height, new_width)\n",
        " \n",
        "    return tf.image.resize(cropped, np_tensor.shape[:2])\n",
        " \n",
        "  augmnted_tensor = random_crop(np_tensor)\n",
        "  return np.array(augmnted_tensor)"
      ],
      "metadata": {
        "id": "OXMw5VpqoE1b"
      },
      "id": "OXMw5VpqoE1b",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=input_shape)\n",
        "# preprocess for mobile net\n",
        "preprocessed_input = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "base_outputs = base_model(preprocessed_input, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(base_outputs)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(num_classes,activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "J_yq-t27nFAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9c9f24-22c0-4a4d-f8a4-2f48363940c0"
      },
      "id": "J_yq-t27nFAa",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 56, 56, 3)]       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 56, 56, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 56, 56, 3)        0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " mobilenet_1.00_224 (Functio  (None, 1, 1, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,239,114\n",
            "Trainable params: 10,250\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHDAHLh7rANl",
        "outputId": "0b78f5f7-7168-4ecb-bda6-233ced01d26b"
      },
      "id": "HHDAHLh7rANl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 19s 9ms/step - loss: 2.2789 - accuracy: 0.1591 - val_loss: 2.2567 - val_accuracy: 0.1970\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 2.2561 - accuracy: 0.1851 - val_loss: 2.2370 - val_accuracy: 0.1887\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 2.2463 - accuracy: 0.1861 - val_loss: 2.2228 - val_accuracy: 0.2140\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 14s 9ms/step - loss: 2.2375 - accuracy: 0.1906 - val_loss: 2.2128 - val_accuracy: 0.2263\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 2.2331 - accuracy: 0.1907 - val_loss: 2.2055 - val_accuracy: 0.2208\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 19s 12ms/step - loss: 2.2259 - accuracy: 0.1911 - val_loss: 2.1984 - val_accuracy: 0.2333\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 2.2256 - accuracy: 0.1917 - val_loss: 2.1948 - val_accuracy: 0.2310\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 2.2220 - accuracy: 0.1920 - val_loss: 2.1901 - val_accuracy: 0.2310\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 2.2222 - accuracy: 0.1921 - val_loss: 2.1871 - val_accuracy: 0.2178\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 15s 9ms/step - loss: 2.2189 - accuracy: 0.1909 - val_loss: 2.1848 - val_accuracy: 0.2020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6df8ab400>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciLz_77QaPSo",
        "outputId": "8b19e2b1-637c-4c2d-c0c8-9969b407f832"
      },
      "id": "ciLz_77QaPSo",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 56, 56, 3)]       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 56, 56, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 56, 56, 3)        0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " mobilenet_1.00_224 (Functio  (None, 1, 1, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,239,114\n",
            "Trainable params: 3,217,226\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzbpgIu5Wkkf",
        "outputId": "7cfbc82b-a156-4d89-a898-11da96940000"
      },
      "id": "QzbpgIu5Wkkf",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 35s 19ms/step - loss: 1.8992 - accuracy: 0.2821 - val_loss: 1.4431 - val_accuracy: 0.5318\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 30s 18ms/step - loss: 0.9985 - accuracy: 0.7216 - val_loss: 0.2560 - val_accuracy: 0.9548\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.2490 - accuracy: 0.9387 - val_loss: 0.1165 - val_accuracy: 0.9673\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 29s 17ms/step - loss: 0.1561 - accuracy: 0.9570 - val_loss: 0.1158 - val_accuracy: 0.9658\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 32s 19ms/step - loss: 0.1281 - accuracy: 0.9637 - val_loss: 0.0956 - val_accuracy: 0.9720\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 30s 18ms/step - loss: 0.1129 - accuracy: 0.9672 - val_loss: 0.0609 - val_accuracy: 0.9817\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 30s 18ms/step - loss: 0.1051 - accuracy: 0.9694 - val_loss: 0.0475 - val_accuracy: 0.9853\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 30s 18ms/step - loss: 0.0913 - accuracy: 0.9722 - val_loss: 0.0418 - val_accuracy: 0.9870\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 30s 18ms/step - loss: 0.0842 - accuracy: 0.9743 - val_loss: 0.0491 - val_accuracy: 0.9838\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 31s 19ms/step - loss: 0.0806 - accuracy: 0.9759 - val_loss: 0.0465 - val_accuracy: 0.9852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb67a182d60>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiYG0xN3b8QQ",
        "outputId": "c0536b6e-c5ce-4185-d4ff-2a00346367e7"
      },
      "id": "eiYG0xN3b8QQ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.05108360946178436\n",
            "Test accuracy: 0.9832000136375427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0])\n",
        "predictions = model.predict([x_test])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Nf2vY5fzcBuF",
        "outputId": "c3f1daaa-dee7-4c04-9e96-7d8e7d61426b"
      },
      "id": "Nf2vY5fzcBuF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7chkr2KGfem8",
        "outputId": "81b76e89-e831-4b02-e732-3eecc533d0b5"
      },
      "id": "7chkr2KGfem8",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.2437278e-06 7.5630282e-06 7.9193969e-06 6.7010092e-06 7.1489285e-07\n",
            " 8.7174121e-06 1.5081440e-07 9.9996316e-01 5.2361520e-07 3.3015920e-06]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}